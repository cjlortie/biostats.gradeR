---
title:
author: "cjlortie"
date: "Oct 2016"
output:
  html_document:
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
---
##BIOL5081: Biostatistics GradeR   

![](./can.do.png)

The goal was statistical thinking through R and good data science. Data frames, EDA, and effective graphics can enhance our capacity to use statistical thinking to solve problems and examine evidence. Real data were used to both practice, time-bounded code (hackathon model), and follow-up revise workflow and analyses.

The purpose of this workflow is to explore whether the philosophy effectively translated into learning and evaluation. The evidence examined were the test scores from each iteration.

###Time-bounded hackathon
```{r, test 1}
library(dplyr)
library(ggplot2)
library(tibble)
library(knitr)
library(fitdistrplus)

#read data
metrics <-read.csv('data/BIOL5081.2016.grades.csv')
#as_tibble(metrics)
hackathon <- metrics %>% filter(metric == "test1")

#table so people can see their scores
kable(hackathon)

#data viz for pattern analysis and exploration of potential stats
ggplot(hackathon, aes(dataset, total)) + 
  geom_boxplot()

ggplot(hackathon, aes(total, colour = dataset)) +
         geom_freqpoly(binwidth = 1.5)

#EDA on distribution
shapiro.test(hackathon$total) 
qqnorm(hackathon$total)
descdist(hackathon$total, boot = 1000)

summary(hackathon)
#mean is 80% and median 84%. Nice!

#variation
m <- mean(hackathon$total)
v<- sd(hackathon$total)
cv <- v/m #coefficient of variation
cv #very small CV for the total scores on code. that is good news.

#frequencies of real dataset use
ggplot(hackathon, aes(dataset)) + geom_bar(stat = "count") + coord_polar() +xlab("") + ylab("")

popular.datasets <- hackathon %>% group_by(dataset) %>% tally() 
#ggplot(popular.datasets, aes(dataset, sort(n))) + 
  #geom_density() + coord_flip() 

#looks like running was most popular
c1<-chisq.test(popular.datasets$dataset, popular.datasets$n)
c1 #no difference but too few observations, so need to simulate

c2<-chisq.test(popular.datasets$dataset, popular.datasets$n, simulate.p.value = TRUE, B = 10000)
c2 #no difference in frequency even with 10,000 replicates of this test

#indication that the dataset related to total score
m1 <- lm(total~dataset, data = hackathon)
summary(m1)
anova(m1, test="Chisq") #no indication that the dataset significantly influenced scores

#however, sample sizes very uneven
m2 <- kruskal.test(total~dataset, data = hackathon)
m2 #still no difference

#Interactive viz using plot.ly or highchart

#final model as lm?

#Note - discovery, these data are messy. Each column is not independent, i.e. the 5 questions scored on the Likert Scale. Need to be tidied up to examine whether a specific dimension was low and thus whether instruction was inadequate or could have been improved.

```



